## OSI与TCP/IP各层的结构与功能,都有哪些协议

### 五层协议的体系结构

学习计算机网络时我们一般采用折中的办法，也就是中和 OSI 和 TCP/IP 的优点，采用一种只有五层协议的体系结构，这样既简洁又能将概念阐述清楚。

[![五层协议的体系结构](https://camo.githubusercontent.com/94ac65420edf518aa8059bae10125db1d0a35c81/68747470733a2f2f757365722d676f6c642d63646e2e786974752e696f2f323031382f372f32392f313634653533303734373165386562613f773d36333326683d33343426663d706e6726733d313634363233)](https://camo.githubusercontent.com/94ac65420edf518aa8059bae10125db1d0a35c81/68747470733a2f2f757365722d676f6c642d63646e2e786974752e696f2f323031382f372f32392f313634653533303734373165386562613f773d36333326683d33343426663d706e6726733d313634363233)

结合互联网的情况，自上而下地，非常简要的介绍一下各层的作用。

### 为什么要三次握手

**三次握手的目的是建立可靠的通信信道，说到通讯，简单来说就是数据的发送与接收，而三次握手最主要的目的就是双方确认自己与对方的发送与接收是正常的。**

第一次握手：Client 什么都不能确认；Server 确认了对方发送正常

第二次握手：Client 确认了：自己发送、接收正常，对方发送、接收正常；Server 确认了：自己接收正常，对方发送正常

第三次握手：Client 确认了：自己发送、接收正常，对方发送、接收正常；Server 确认了：自己发送、接收正常，对方发送接收正常

所以三次握手就能确认双发收发功能都正常，缺一不可。

### 为什么要传回 SYN

接收端传回发送端所发送的 SYN 是为了告诉发送端，我接收到的信息确实就是你所发送的信号了。

SYN 是 TCP/IP 建立连接时使用的握手信号。在客户机和服务器之间建立正常的 TCP 网络连接时，客户机首先发出一个 SYN 消息，服务器使用 SYN-ACK 应答表示接收到了这个消息，最后客户机再以 ACK(Acknowledgement 消息响应。这样在客户机和服务器之间才能建立起可靠的TCP连接，数据才可以在客户机和服务器之间传递。

### 传了 SYN,为啥还要传 ACK

双方通信无误必须是两者互相发送信息都无误。传了 SYN，证明发送方到接收方的通道没有问题，但是接收方到发送方的通道还需要 ACK 信号来进行验证。

### 为什么要四次挥手

任何一方都可以在数据传送结束后发出连接释放的通知，待对方确认后进入半关闭状态。当另一方也没有数据再发送的时候，则发出连接释放通知，对方确认后就完全关闭了TCP连接。

断开一个 TCP 连接则需要“四次挥手”：

- 客户端-发送一个 FIN，用来关闭客户端到服务器的数据传送
- 服务器-收到这个 FIN，它发回一 个 ACK，确认序号为收到的序号加1 。和 SYN 一样，一个 FIN 将占用一个序号
- 服务器-关闭与客户端的连接，发送一个FIN给客户端
- 客户端-发回 ACK 报文确认，并将确认序号设置为收到序号加1

## TCP、UDP 协议的区别

[![TCP、UDP协议的区别](https://camo.githubusercontent.com/409f705f6df8c77c7166e543eefa07c40511a28a/68747470733a2f2f757365722d676f6c642d63646e2e786974752e696f2f323031382f342f31392f313632646235653937653961396530313f696d61676556696577322f302f772f313238302f682f3936302f666f726d61742f776562702f69676e6f72652d6572726f722f31)](https://camo.githubusercontent.com/409f705f6df8c77c7166e543eefa07c40511a28a/68747470733a2f2f757365722d676f6c642d63646e2e786974752e696f2f323031382f342f31392f313632646235653937653961396530313f696d61676556696577322f302f772f313238302f682f3936302f666f726d61742f776562702f69676e6f72652d6572726f722f31)

UDP 在传送数据之前不需要先建立连接，远地主机在收到 UDP 报文后，不需要给出任何确认。虽然 UDP 不提供可靠交付，但在某些情况下 UDP 确是一种最有效的工作方式（一般用于即时通信），比如： QQ 语音、 QQ 视频 、直播等等

TCP 提供面向连接的服务。在传送数据之前必须先建立连接，数据传送结束后要释放连接。 TCP 不提供广播或多播服务。由于 TCP 要提供可靠的，面向连接的运输服务（TCP的可靠体现在TCP在传递数据之前，会有三次握手来建立连接，而且在数据传递时，有确认、窗口、重传、拥塞控制机制，在数据传完后，还会断开连接用来节约系统资源），这一难以避免增加了许多开销，如确认，流量控制，计时器以及连接管理等。这不仅使协议数据单元的首部增大很多，还要占用许多处理机资源。TCP 一般用于文件传输、发送和接收邮件、远程登录等场景。

## TCP 协议如何保证可靠传输

1. 应用数据被分割成 TCP 认为最适合发送的数据块。
2. TCP 给发送的每一个包进行编号，接收方对数据包进行排序，把有序数据传送给应用层。
3. **校验和：** TCP 将保持它首部和数据的检验和。这是一个端到端的检验和，目的是检测数据在传输过程中的任何变化。如果收到段的检验和有差错，TCP 将丢弃这个报文段和不确认收到此报文段。
4. TCP 的接收端会丢弃重复的数据。
5. **流量控制：** TCP 连接的每一方都有固定大小的缓冲空间，TCP的接收端只允许发送端发送接收端缓冲区能接纳的数据。当接收方来不及处理发送方的数据，能提示发送方降低发送的速率，防止包丢失。TCP 使用的流量控制协议是可变大小的滑动窗口协议。 （TCP 利用滑动窗口实现流量控制）
6. **拥塞控制：** 当网络拥塞时，减少数据的发送。
7. **停止等待协议** 也是为了实现可靠传输的，它的基本原理就是每发完一个分组就停止发送，等待对方确认。在收到确认后再发下一个分组。 **超时重传：** 当 TCP 发出一个段后，它启动一个定时器，等待目的端确认收到这个报文段。如果不能及时收到一个确认，将重发这个报文段。

### 停止等待协议

- 停止等待协议是为了实现可靠传输的，它的基本原理就是每发完一个分组就停止发送，等待对方确认。在收到确认后再发下一个分组；
- 在停止等待协议中，若接收方收到重复分组，就丢弃该分组，但同时还要发送确认；

**1) 无差错情况:**

[![img](https://camo.githubusercontent.com/87a4e3d99e9e650c22572eb8ba3ccf74feb86d30/68747470733a2f2f757365722d676f6c642d63646e2e786974752e696f2f323031382f382f31362f313635343166613863333831366139303f773d35313426683d34373326663d706e6726733d39393234)](https://camo.githubusercontent.com/87a4e3d99e9e650c22572eb8ba3ccf74feb86d30/68747470733a2f2f757365722d676f6c642d63646e2e786974752e696f2f323031382f382f31362f313635343166613863333831366139303f773d35313426683d34373326663d706e6726733d39393234)

发送方发送分组,接收方在规定时间内收到,并且回复确认.发送方再次发送。

**2) 出现差错情况（超时重传）:** [![img](https://camo.githubusercontent.com/b499ea2d7d33b0d69af03f8dbdec2321f811d1a0/68747470733a2f2f757365722d676f6c642d63646e2e786974752e696f2f323031382f382f31362f313635343166616566646632343961623f773d39353326683d34383026663d706e6726733d3139313633)](https://camo.githubusercontent.com/b499ea2d7d33b0d69af03f8dbdec2321f811d1a0/68747470733a2f2f757365722d676f6c642d63646e2e786974752e696f2f323031382f382f31362f313635343166616566646632343961623f773d39353326683d34383026663d706e6726733d3139313633)停止等待协议中超时重传是指只要超过一段时间仍然没有收到确认，就重传前面发送过的分组（认为刚才发送过的分组丢失了）。因此每发送完一个分组需要设置一个超时计时器，其重转时间应比数据在分组传输的平均往返时间更长一些。这种自动重传方式常称为 **自动重传请求 ARQ** 。另外在停止等待协议中若收到重复分组，就丢弃该分组，但同时还要发送确认。**连续 ARQ 协议** 可提高信道利用率。发送维持一个发送窗口，凡位于发送窗口内的分组可连续发送出去，而不需要等待对方确认。接收方一般采用累积确认，对按序到达的最后一个分组发送确认，表明到这个分组位置的所有分组都已经正确收到了。

**3) 确认丢失和确认迟到**

- **确认丢失**：确认消息在传输过程丢失 [![img](https://camo.githubusercontent.com/860937399b9aee59e78044f0c323cb0e24d6f5b7/68747470733a2f2f757365722d676f6c642d63646e2e786974752e696f2f323031382f382f31362f313635343166623639343161373136353f773d39313826683d34363126663d706e6726733d3139383431)](https://camo.githubusercontent.com/860937399b9aee59e78044f0c323cb0e24d6f5b7/68747470733a2f2f757365722d676f6c642d63646e2e786974752e696f2f323031382f382f31362f313635343166623639343161373136353f773d39313826683d34363126663d706e6726733d3139383431)当A发送M1消息，B收到后，B向A发送了一个M1确认消息，但却在传输过程中丢失。而A并不知道，在超时计时过后，A重传M1消息，B再次收到该消息后采取以下两点措施：
  1. 丢弃这个重复的M1消息，不向上层交付。
  2. 向A发送确认消息。（不会认为已经发送过了，就不再发送。A能重传，就证明B的确认消息丢失）。
- **确认迟到** ：确认消息在传输过程中迟到 [![img](https://camo.githubusercontent.com/26a9448d6b1d283bb0490a0c50630f88fde885fa/68747470733a2f2f757365722d676f6c642d63646e2e786974752e696f2f323031382f382f31362f313635343166646438353932396536623f773d38393926683d34353026663d706e6726733d3233313635)](https://camo.githubusercontent.com/26a9448d6b1d283bb0490a0c50630f88fde885fa/68747470733a2f2f757365722d676f6c642d63646e2e786974752e696f2f323031382f382f31362f313635343166646438353932396536623f773d38393926683d34353026663d706e6726733d3233313635)A发送M1消息，B收到并发送确认。在超时时间内没有收到确认消息，A重传M1消息，B仍然收到并继续发送确认消息（B收到了2份M1）。此时A收到了B第二次发送的确认消息。接着发送其他数据。过了一会，A收到了B第一次发送的对M1的确认消息（A也收到了2份确认消息）。处理如下：
  1. A收到重复的确认后，直接丢弃。
  2. B收到重复的M1后，也直接丢弃重复的M1。

### 自动重传请求 ARQ 协议

停止等待协议中超时重传是指只要超过一段时间仍然没有收到确认，就重传前面发送过的分组（认为刚才发送过的分组丢失了）。因此每发送完一个分组需要设置一个超时计时器，其重转时间应比数据在分组传输的平均往返时间更长一些。这种自动重传方式常称为自动重传请求ARQ。

**优点：** 简单

**缺点：** 信道利用率低

### 连续ARQ协议

连续 ARQ 协议可提高信道利用率。发送方维持一个发送窗口，凡位于发送窗口内的分组可以连续发送出去，而不需要等待对方确认。接收方一般采用累计确认，对按序到达的最后一个分组发送确认，表明到这个分组为止的所有分组都已经正确收到了。

**优点：** 信道利用率高，容易实现，即使确认丢失，也不必重传。

**缺点：** 不能向发送方反映出接收方已经正确收到的所有分组的信息。 比如：发送方发送了 5条 消息，中间第三条丢失（3号），这时接收方只能对前两个发送确认。发送方无法知道后三个分组的下落，而只好把后三个全部重传一次。这也叫 Go-Back-N（回退 N），表示需要退回来重传已经发送过的 N 个消息。

### 滑动窗口

- TCP 利用滑动窗口实现流量控制的机制。
- 滑动窗口（Sliding window）是一种流量控制技术。早期的网络通信中，通信双方不会考虑网络的拥挤情况直接发送数据。由于大家不知道网络拥塞状况，同时发送数据，导致中间节点阻塞掉包，谁也发不了数据，所以就有了滑动窗口机制来解决此问题。
- TCP 中采用滑动窗口来进行传输控制，滑动窗口的大小意味着接收方还有多大的缓冲区可以用于接收数据。发送方可以通过滑动窗口的大小来确定应该发送多少字节的数据。当滑动窗口为 0 时，发送方一般不能再发送数据报，但有两种情况除外，一种情况是可以发送紧急数据，例如，允许用户终止在远端机上的运行进程。另一种情况是发送方可以发送一个 1 字节的数据报来通知接收方重新声明它希望接收的下一字节及发送方的滑动窗口大小。

### 流量控制

- TCP 利用滑动窗口实现流量控制。
- 流量控制是为了控制发送方发送速率，保证接收方来得及接收。
- 接收方发送的确认报文中的窗口字段可以用来控制发送方窗口大小，从而影响发送方的发送速率。将窗口字段设置为 0，则发送方不能发送数据。

### 拥塞控制

在某段时间，若对网络中某一资源的需求超过了该资源所能提供的可用部分，网络的性能就要变坏。这种情况就叫拥塞。拥塞控制就是为了防止过多的数据注入到网络中，这样就可以使网络中的路由器或链路不致过载。拥塞控制所要做的都有一个前提，就是网络能够承受现有的网络负荷。拥塞控制是一个全局性的过程，涉及到所有的主机，所有的路由器，以及与降低网络传输性能有关的所有因素。相反，流量控制往往是点对点通信量的控制，是个端到端的问题。流量控制所要做到的就是抑制发送端发送数据的速率，以便使接收端来得及接收。

为了进行拥塞控制，TCP 发送方要维持一个 **拥塞窗口(cwnd)** 的状态变量。拥塞控制窗口的大小取决于网络的拥塞程度，并且动态变化。发送方让自己的发送窗口取为拥塞窗口和接收方的接受窗口中较小的一个。

TCP的拥塞控制采用了四种算法，即 **慢开始** 、 **拥塞避免** 、**快重传** 和 **快恢复**。在网络层也可以使路由器采用适当的分组丢弃策略（如主动队列管理 AQM），以减少网络拥塞的发生。

- **慢开始：** 慢开始算法的思路是当主机开始发送数据时，如果立即把大量数据字节注入到网络，那么可能会引起网络阻塞，因为现在还不知道网络的符合情况。经验表明，较好的方法是先探测一下，即由小到大逐渐增大发送窗口，也就是由小到大逐渐增大拥塞窗口数值。cwnd初始值为1，每经过一个传播轮次，cwnd加倍。 [![img](https://camo.githubusercontent.com/b6c00ee83a30ceb0ac1abc459a14a6167957b8a9/68747470733a2f2f757365722d676f6c642d63646e2e786974752e696f2f323031382f382f31302f313635323334386164613263386664303f773d3130353026683d35363026663d6a70656726733d313132363131)](https://camo.githubusercontent.com/b6c00ee83a30ceb0ac1abc459a14a6167957b8a9/68747470733a2f2f757365722d676f6c642d63646e2e786974752e696f2f323031382f382f31302f313635323334386164613263386664303f773d3130353026683d35363026663d6a70656726733d313132363131)
- **拥塞避免：** 拥塞避免算法的思路是让拥塞窗口cwnd缓慢增大，即每经过一个往返时间RTT就把发送放的cwnd加1.
- **快重传与快恢复：** 在 TCP/IP 中，快速重传和恢复（fast retransmit and recovery，FRR）是一种拥塞控制算法，它能快速恢复丢失的数据包。没有 FRR，如果数据包丢失了，TCP 将会使用定时器来要求传输暂停。在暂停的这段时间内，没有新的或复制的数据包被发送。有了 FRR，如果接收机接收到一个不按顺序的数据段，它会立即给发送机发送一个重复确认。如果发送机接收到三个重复确认，它会假定确认件指出的数据段丢失了，并立即重传这些丢失的数据段。有了 FRR，就不会因为重传时要求的暂停被耽误。 　当有单独的数据包丢失时，快速重传和恢复（FRR）能最有效地工作。当有多个数据信息包在某一段很短的时间内丢失时，它则不能很有效地工作。 [![快重传与快恢复](https://camo.githubusercontent.com/221825b6068e180c2fd6d4909d417bc5c6c8c2b9/68747470733a2f2f757365722d676f6c642d63646e2e786974752e696f2f323031382f382f31302f313635323334663033303364313734623f773d3131373426683d36343826663d706e6726733d313039353638)](https://camo.githubusercontent.com/221825b6068e180c2fd6d4909d417bc5c6c8c2b9/68747470733a2f2f757365722d676f6c642d63646e2e786974752e696f2f323031382f382f31302f313635323334663033303364313734623f773d3131373426683d36343826663d706e6726733d313039353638)

## 在浏览器中输入url地址 ->> 显示主页的过程

打开一个网页，整个过程会使用哪些协议

总体来说分为以下几个过程:

1. DNS解析
2. TCP连接
3. 发送HTTP请求
4. 服务器处理请求并返回HTTP报文
5. 浏览器解析渲染页面
6. 连接结束

### 具体过程

#### DNS解析

DNS解析的过程就是寻找哪台机器上有你需要资源的过程。互联网设计者需要在用户的方便性与可用性方面做一个权衡，这个权衡就是一个网址到IP地址的转换，这个过程就是DNS解析。它实际上充当了一个翻译的角色，实现了网址到IP地址的转换。

#### 解析过程

DNS解析是一个递归查询的过程。

![DNS解析过程](https://segmentfault.com/img/bVDM45?w=1928&h=1248)

上述图片是查找www.google.com的IP地址过程。首先在本地域名服务器中查询IP地址，如果没有找到的情况下，本地域名服务器会向根域名服务器发送一个请求，如果根域名服务器也不存在该域名时，本地域名会向com顶级域名服务器发送一个请求，依次类推下去。直到最后本地域名服务器得到google的IP地址并把它缓存到本地，供下次查询使用。从上述过程中，可以看出网址的解析是一个从右向左的过程: com -> google.com -> www.google.com。但是你是否发现少了点什么，根域名服务器的解析过程呢？事实上，真正的网址是www.google.com.，并不是我多打了一个.，这个.对应的就是根域名服务器，默认情况下所有的网址的最后一位都是.，既然是默认情况下，为了方便用户，通常都会省略，浏览器在请求DNS的时候会自动加上，所有网址真正的解析过程为: . -> .com -> google.com. -> www.google.com.。

#### DNS优化

了解了DNS的过程，可以为我们带来哪些？上文中请求到google的IP地址时，经历了8个步骤，这个过程中存在多个请求(同时存在UDP和TCP请求，为什么有两种请求方式，请自行查找)。如果每次都经过这么多步骤，是否太耗时间？如何减少该过程的步骤呢？那就是DNS缓存。

##### DNS缓存

DNS存在着多级缓存，从离浏览器的距离排序的话，有以下几种:

- 浏览器缓存
- 系统缓存
- 路由器缓存
- IPS服务器缓存
- 根域名服务器缓存
- 顶级域名服务器缓存
- 主域名服务器缓存。

1. 在你的chrome浏览器中输入:chrome://dns/，你可以看到chrome浏览器的DNS缓存。
2. 系统缓存主要存在/etc/hosts(Linux系统)中:

![DNS系统缓存](https://segmentfault.com/img/bVDM5c?w=956&h=366)

- ...

##### DNS负载均衡

不知道大家有没有思考过一个问题: DNS返回的IP地址是否每次都一样？如果每次都一样是否说明你请求的资源都位于同一台机器上面，那么这台机器需要多高的性能和储存才能满足亿万请求呢？其实真实的互联网世界背后存在成千上百台服务器，大型的网站甚至更多。但是在用户的眼中，它需要的只是处理他的请求，哪台机器处理请求并不重要。DNS可以返回一个合适的机器的IP给用户，例如可以根据每台机器的负载量，该机器离用户地理位置的距离等等，这种过程就是DNS负载均衡，又叫做DNS重定向。大家耳熟能详的CDN(Content Delivery Network)就是利用DNS的重定向技术，DNS服务器会返回一个跟用户最接近的点的IP地址给用户，CDN节点的服务器负责响应用户的请求，提供所需的内容。在这里打个免费的广告，我平时使用的比较多的是七牛云的CDN(免费)储存图片，作为我个人博客的图床使用。

#### TCP连接

HTTP协议是使用TCP作为其传输层协议的，当TCP出现瓶颈时，HTTP也会受到影响。

#### HTTPS过程

HTTPS在传输数据之前需要客户端与服务器进行一个握手(TLS/SSL握手)，在握手过程中将确立双方加密传输数据的密码信息。TLS/SSL使用了非对称加密，对称加密以及hash等。具体过程请参考经典的阮一峰先生的博客[TLS/SSL握手过程](http://www.ruanyifeng.com/blog/2014/09/illustration-ssl.html)。
HTTPS相比于HTTP，虽然提供了安全保证，但是势必会带来一些时间上的损耗，如握手和加密等过程，是否使用HTTPS需要根据具体情况在安全和性能方面做出权衡。

##### HTTP请求

其实这部分又可以称为前端工程师眼中的HTTP，它主要发生在客户端。发送HTTP请求的过程就是构建HTTP请求报文并通过TCP协议中发送到服务器指定端口(HTTP协议80/8080, HTTPS协议443)。HTTP请求报文是由三部分组成: **请求行**, **请求报头**和**请求正文**。

#### 服务器处理请求并返回HTTP报文

自然而然这部分对应的就是后端工程师眼中的HTTP。后端从在固定的端口接收到TCP报文开始，这一部分对应于编程语言中的socket。它会对TCP连接进行处理，对HTTP协议进行解析，并按照报文格式进一步封装成HTTP Request对象，供上层使用。这一部分工作一般是由Web服务器去进行，我使用过的Web服务器有Tomcat, Jetty和Netty等等。

HTTP响应报文也是由三部分组成: **状态码**, **响应报头**和**响应报文**。

##### Spring MVC中处理步骤：

1. 发起请求到前端控制器(`DispatcherServlet`)
2. 前端控制器请求处理器映射器(`HandlerMapping`)查找`Handler`(可根据xml配置、注解进行查找)
3. 处理器映射器(`HandlerMapping`)向前端控制器返回`Handler`
4. 前端控制器调用处理器适配器(`HandlerAdapter`)执行`Handler`
5. 处理器适配器(HandlerAdapter)去执行Handler
6. Handler执行完，给适配器返回ModelAndView(Springmvc框架的一个底层对象)
7. 处理器适配器(`HandlerAdapter`)向前端控制器返回`ModelAndView`
8. 前端控制器(`DispatcherServlet`)请求视图解析器(`ViewResolver`)进行视图解析，根据逻辑视图名解析成真正的视图(jsp)
9. 视图解析器(ViewResolver)向前端控制器(`DispatcherServlet`)返回View
10. 前端控制器进行视图渲染，即将模型数据(在`ModelAndView`对象中)填充到request域
11. 前端控制器向用户响应结果

#### 浏览器解析渲染页面

浏览器在收到HTML,CSS,JS文件后，它是如何把页面呈现到屏幕上的？下图对应的就是WebKit渲染的过程。

![WebKit渲染过程](https://segmentfault.com/img/bVCZ1H?w=694&h=340)

浏览器是一个边解析边渲染的过程。首先浏览器解析HTML文件构建DOM树，然后解析CSS文件构建渲染树，等到渲染树构建完成后，浏览器开始布局渲染树并将其绘制到屏幕上。这个过程比较复杂，涉及到两个概念: reflow(回流)和repain(重绘)。DOM节点中的各个元素都是以盒模型的形式存在，这些都需要浏览器去计算其位置和大小等，这个过程称为relow;当盒模型的位置,大小以及其他属性，如颜色,字体,等确定下来之后，浏览器便开始绘制内容，这个过程称为repain。页面在首次加载时必然会经历reflow和repain。reflow和repain过程是非常消耗性能的，尤其是在移动设备上，它会破坏用户体验，有时会造成页面卡顿。所以我们应该尽可能少的减少reflow和repain。

![Event loop](https://segmentfault.com/img/bVC1uE?w=734&h=689)

JS的解析是由浏览器中的JS解析引擎完成的。JS是单线程运行，也就是说，在同一个时间内只能做一件事，所有的任务都需要排队，前一个任务结束，后一个任务才能开始。但是又存在某些任务比较耗时，如IO读写等，所以需要一种机制可以先执行排在后面的任务，这就是：同步任务(synchronous)和异步任务(asynchronous)。JS的执行机制就可以看做是一个主线程加上一个任务队列(task queue)。同步任务就是放在主线程上执行的任务，异步任务是放在任务队列中的任务。所有的同步任务在主线程上执行，形成一个执行栈;异步任务有了运行结果就会在任务队列中放置一个事件；脚本运行时先依次运行执行栈，然后会从任务队列里提取事件，运行任务队列中的任务，这个过程是不断重复的，所以又叫做事件循环(Event loop)。

浏览器在解析过程中，如果遇到请求外部资源时，如图像,iconfont,JS等。浏览器将重复1-6过程下载该资源。请求过程是异步的，并不会影响HTML文档进行加载，但是当文档加载过程中遇到JS文件，HTML文档会挂起渲染过程，不仅要等到文档中JS文件加载完毕还要等待解析执行完毕，才会继续HTML的渲染过程。原因是因为JS有可能修改DOM结构，这就意味着JS执行完成前，后续所有资源的下载是没有必要的，这就是JS阻塞后续资源下载的根本原因。CSS文件的加载不影响JS文件的加载，但是却影响JS文件的执行。JS代码执行前浏览器必须保证CSS文件已经下载并加载完毕。

参考这篇文章：

- [https://segmentfault.com/a/1190000006879700](https://segmentfault.com/a/1190000006879700)

## HTTP长连接、短连接

在HTTP/1.0中默认使用短连接。也就是说，客户端和服务器每进行一次HTTP操作，就建立一次连接，任务结束就中断连接。当客户端浏览器访问的某个HTML或其他类型的Web页中包含有其他的Web资源（如JavaScript文件、图像文件、CSS文件等），每遇到这样一个Web资源，浏览器就会重新建立一个HTTP会话。

而从HTTP/1.1起，默认使用长连接，用以保持连接特性。使用长连接的HTTP协议，会在响应头加入这行代码：

```
Connection:keep-alive

```

在使用长连接的情况下，当一个网页打开完成后，客户端和服务器之间用于传输HTTP数据的TCP连接不会关闭，客户端再次访问这个服务器时，会继续使用这一条已经建立的连接。Keep-Alive不会永久保持连接，它有一个保持时间，可以在不同的服务器软件（如Apache）中设定这个时间。实现长连接需要客户端和服务端都支持长连接。

**HTTP协议的长连接和短连接，实质上是TCP协议的长连接和短连接。**

## HTTP和HTTPS的区别

## TCP三次握手和四次挥手面试问题

描述一下三次握手的过程；

描述一下握手报文里都有哪些关键字段，能够说出ISN这个关键词， 接着问；

**ISN代表什么？意义何在？**

ISN，发送方的字节数据编号的原点，让对方生成一个合法的接收窗口。

**ISN是固定不变的吗？**

动态随机。

**ISN为何要动态随机？**

增加安全性，为了避免被第三方猜测到，从而被第三方伪造的RST报文Reset。

**还有吗？**

ISN动态随机使得每个tcp session的字节序列号没有重叠，如果出现tcp五元组冲突这种极小概率情况的发生，一个session的数据也不会被误认为是另一个session的。

**刚才你提到第三方可以伪造RST报文，需要满足什么条件才能得逞？**

需要sequence number 位于对方的合法接收窗口内。 而由于ISN是动态随机的，猜出对方合法接收窗口难度加大。

如果ISN = 0，那么猜出的难度就大大降低。

**三次握手的第一次可以携带数据吗？为何？**

**不可以，三次握手还没有完成。**

**对方难道不可以将数据缓存下来，等握手成功再提交给应用程序？**

这样会放大SYN FLOOD攻击。

如果攻击者伪造了成千上万的握手报文，携带了1K+ 字节的数据，而接收方会开辟大量的缓存来容纳这些巨大数据，内存会很容易耗尽，从而拒绝服务。

**第三次可以携带数据吗？为何？**

可以。

能够发出第三次握手报文的主机，肯定接收到第二次(服务器)握手报文，对吗？

因为伪造IP的主机是不会接收到第二次报文的。

所以，能够发出第三次握手报文的，应该是合法的用户。

尽管服务器侧的状态还没有“established”，接收到第三次握手的瞬间，状态就会切换为“established”，里面携带的数据按照正常流程走就好。  

**看到有人说，只看到过TCP状态位为** **’FIN +ACK’，但从来没有看过状态位只有** **‘FIN’，你应该怎样给他解释？**

RFC793明确规定，除了第一个握手报文SYN除外，其它所有报文必须将ACK = 1。

**很好，RFC规定的背后肯定有合理性的一面，能否深究一下原因？**

TCP作为一个可靠传输协议，其可靠性就是依赖于收到对方的数据，ACK对方，这样对方就可以释放缓存的数据，因为对方确信数据已经被接收到了。

但TCP报文是在IP网络上传输，丢包是家常便饭，接收方**要抓住一切的机会，把消息告诉发送方**。最方便的方式就是，任何我方发送的TCP报文，都要捎带着ACK状态位。

**ACK状态位单独能承担这个消息传递的任务吗？**

不能！需要有 Acknowledge Number配合才行。

如果我方发出的Acknowledge Number == 10001，那意味着序列号10000及之前的字节已经成功接收。

如果对方占据字节序列号10000是应用层数据，那么就是确认应用层数据。

如果对方占据字节序列号10000是’FIN’状态位，那么就是确认接收到对方的’FIN’。

## TCP粘包和拆包

粘包/拆包现象：

客户端发送两个数据包D1和D2到服务器，会出现以下4种情况：

1. 服务端分两次读取，获得两个独立的数据包，分别D1和D2，这种情况下没有粘包/拆包问题。
2. 服务端一共就读到了一个数据包，这个数据包是D1和D2的完整信息，这样D1和D2粘合在一起，因为服务端不知道第一条消息从哪儿结束和第二条消息从哪儿开始，所以发生了TCP粘包。
3. 服务端分两次读取到了两个数据包，第一次读取到了完整的D1包和D2包的前半部分D2_1，第二次读取到了D2包的剩余部分D2_2，这被称为TCP拆包。
4. 服务端分两次读取到了两个数据包，第一次读取到了D1包的前半部分D1_1，第二次读取到了D1包的剩余部分D1_2和D2包的整包，这也被称为TCP拆包。

发生粘包/拆包的主要原因：

1. 应用程序写入的数据大于套接字缓冲区大小，这将会发生拆包。
2. 应用程序写入数据小于套接字缓冲区大小，网卡将应用多次写入的数据发送到网络上，这将会发生粘包。
3. 进行MSS（最大报文长度）大小的TCP分段，当TCP报文长度-TCP头部长度>MSS的时候将发生拆包。
4. 接收方不及时读取套接字缓冲区数据，这将发生粘包。

粘包/拆包问题的解决策略

通过上层的**应用协议栈**来解决。

1. 消息定长。例如每个报文的大小为固定长度200字节，如果不够，空位补空格。
2. 在包尾增加回车换行符进行分割，例如FTP协议。
3. 设置消息边界，服务端从网络流中按消息边界分离出消息内容。
4. 将消息分为消息头和消息体，消息头中包含表示消息总长度（或者消息体长度）的字段。
5. 更复杂的应用层协议。

## 代理和反向代理

正向代理是代理客户端，为客户端收发请求，使真实客户端对服务器不可见；而反向代理是代理服务器端，为服务器收发请求，使真实服务器对客户端不可见。

正向代理中，proxy和client同属一个LAN，对server透明； 反向代理中，proxy和server同属一个LAN，对client透明。

从用途上来区分：

- 正向代理：正向代理用途是为了在防火墙内的局域网提供访问internet的途径。另外还可以使用缓冲特性减少网络使用率
- 反向代理：反向代理的用途是将防火墙后面的服务器提供给internet用户访问。同时还可以完成诸如负载均衡等功能

  从安全性来讲：

- 正向代理：正向代理允许客户端通过它访问任意网站并且隐蔽客户端自身，因此你必须采取安全措施来确保仅为经过授权的客户端提供服务
- 反向代理：对外是透明的，访问者并不知道自己访问的是代理。对访问者而言，他以为访问的就是原始服务器





