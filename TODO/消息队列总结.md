# 消息队列总结

# 什么叫消息队列

消息（Message）是指在应用间传送的数据。消息可以非常简单，比如只包含文本字符串，也可以更复杂，可能包含嵌入对象。

消息队列（Message Queue）是一种应用间的通信方式，消息发送后可以立即返回，由消息系统来确保消息的可靠传递。消息发布者只管把消息发布到 MQ 中而不用管谁来取，消息使用者只管从 MQ 中取消息而不管是谁发布的。这样发布者和使用者都不用知道对方的存在。

# 为何用消息队列

从上面的描述中可以看出消息队列是一种应用间的异步协作机制，那什么时候需要使用 MQ 呢？

以常见的订单系统为例，用户点击【下单】按钮之后的业务逻辑可能包括：扣减库存、生成相应单据、发红包、发短信通知。在业务发展初期这些逻辑可能放在一起同步执行，随着业务的发展订单量增长，需要提升系统服务的性能，这时可以将一些不需要立即生效的操作拆分出来异步执行，比如发放红包、发短信通知等。这种场景下就可以用 MQ ，在下单的主流程（比如扣减库存、生成相应单据）完成之后发送一条消息到 MQ 让主流程快速完结，而由另外的单独线程拉取MQ的消息（或者由 MQ 推送消息），当发现 MQ 中有发红包或发短信之类的消息时，执行相应的业务逻辑。

以上是用于业务解耦的情况，其它常见场景包括最终一致性、广播、错峰流控等等。

# RabbitMQ 特点

RabbitMQ 是一个由 Erlang 语言开发的 AMQP 的开源实现。

AMQP ：Advanced Message Queue，高级消息队列协议。它是应用层协议的一个开放标准，为面向消息的中间件设计，基于此协议的客户端与消息中间件可传递消息，并不受产品、开发语言等条件的限制。

RabbitMQ 最初起源于金融系统，用于在分布式系统中存储转发消息，在易用性、扩展性、高可用性等方面表现不俗。具体特点包括：

1. 可靠性（Reliability）RabbitMQ 使用一些机制来保证可靠性，如持久化、传输确认、发布确认。
2. 灵活的路由（Flexible Routing）在消息进入队列之前，通过 Exchange 来路由消息的。对于典型的路由功能，RabbitMQ 已经提供了一些内置的 Exchange 来实现。针对更复杂的路由功能，可以将多个 Exchange 绑定在一起，也通过插件机制实现自己的 Exchange 。
3. 消息集群（Clustering）多个 RabbitMQ 服务器可以组成一个集群，形成一个逻辑 Broker 。
4. 高可用（Highly Available Queues）队列可以在集群中的机器上进行镜像，使得在部分节点出问题的情况下队列仍然可用。
5. 多种协议（Multi-protocol）RabbitMQ 支持多种消息队列协议，比如 STOMP、MQTT 等等。
6. 多语言客户端（Many Clients）RabbitMQ 几乎支持所有常用语言，比如 Java、.NET、Ruby 等等。
7. 管理界面（Management UI）RabbitMQ 提供了一个易用的用户界面，使得用户可以监控和管理消息 Broker 的许多方面。
8. 跟踪机制（Tracing）如果消息异常，RabbitMQ 提供了消息跟踪机制，使用者可以找出发生了什么。
9. 插件机制（Plugin System）RabbitMQ 提供了许多插件，来从多方面进行扩展，也可以编写自己的插件。

# RabbitMQ 中的概念

### 消息模型

所有 MQ 产品从模型抽象上来说都是一样的过程：消费者（consumer）订阅某个队列。生产者（producer）创建消息，然后发布到队列（queue）中，最后将消息发送到监听的消费者。

![消息流](https://user-gold-cdn.xitu.io/2018/1/24/161260568dd200d6?imageView2/0/w/1280/h/960/format/webp/ignore-error/1)

### RabbitMQ 基本概念

上面只是最简单抽象的描述，具体到 RabbitMQ 则有更详细的概念需要解释。上面介绍过 RabbitMQ 是 AMQP 协议的一个开源实现，所以其内部实际上也是 AMQP 中的基本概念：

![RabbitMQ 内部结构](https://user-gold-cdn.xitu.io/2018/1/24/161260568dd66584?imageView2/0/w/1280/h/960/format/webp/ignore-error/1)

1. Message消息，消息是不具名的，它由消息头和消息体组成。消息体是不透明的，而消息头则由一系列的可选属性组成，这些属性包括routing-key（路由键）、priority（相对于其他消息的优先权）、delivery-mode（指出该消息可能需要持久性存储）等。
2. Publisher消息的生产者，也是一个向交换器发布消息的客户端应用程序。
3. Exchange交换器，用来接收生产者发送的消息并将这些消息路由给服务器中的队列。
4. Binding绑定，用于消息队列和交换器之间的关联。一个绑定就是基于路由键将交换器和消息队列连接起来的路由规则，所以可以将交换器理解成一个由绑定构成的路由表。
5. Queue消息队列，用来保存消息直到发送给消费者。它是消息的容器，也是消息的终点。一个消息可投入一个或多个队列。消息一直在队列里面，等待消费者连接到这个队列将其取走。
6. Connection网络连接，比如一个TCP连接。
7. Channel信道，多路复用连接中的一条独立的双向数据流通道。信道是建立在真实的TCP连接内地虚拟连接，AMQP 命令都是通过信道发出去的，不管是发布消息、订阅队列还是接收消息，这些动作都是通过信道完成。因为对于操作系统来说建立和销毁 TCP 都是非常昂贵的开销，所以引入了信道的概念，以复用一条 TCP 连接。
8. Consumer消息的消费者，表示一个从消息队列中取得消息的客户端应用程序。
9. Virtual Host虚拟主机，表示一批交换器、消息队列和相关对象。虚拟主机是共享相同的身份认证和加密环境的独立服务器域。每个 vhost 本质上就是一个 mini 版的 RabbitMQ 服务器，拥有自己的队列、交换器、绑定和权限机制。vhost 是 AMQP 概念的基础，必须在连接时指定，RabbitMQ 默认的 vhost 是 / 。
10. Broker表示消息队列服务器实体。

#### AMQP 中的消息路由

AMQP 中消息的路由过程和 Java 开发者熟悉的 JMS 存在一些差别，AMQP 中增加了 Exchange 和 Binding 的角色。生产者把消息发布到 Exchange 上，消息最终到达队列并被消费者接收，而 Binding 决定交换器的消息应该发送到那个队列。

![AMQP 的消息路由过程](https://user-gold-cdn.xitu.io/2018/1/24/161260568e434217?imageView2/0/w/1280/h/960/format/webp/ignore-error/1)

#### Exchange 类型

Exchange分发消息时根据类型的不同分发策略有区别，目前共四种类型：direct、fanout、topic、headers 。headers 匹配 AMQP 消息的 header 而不是路由键，此外 headers 交换器和 direct 交换器完全一致，但性能差很多，目前几乎用不到了，所以直接看另外三种类型：

1. direct![direct 交换器](https://user-gold-cdn.xitu.io/2018/1/24/161260568dc498b6?imageView2/0/w/1280/h/960/format/webp/ignore-error/1)消息中的路由键（routing key）如果和 Binding 中的 binding key 一致， 交换器就将消息发到对应的队列中。路由键与队列名完全匹配，如果一个队列绑定到交换机要求路由键为“dog”，则只转发 routing key 标记为“dog”的消息，不会转发“dog.puppy”，也不会转发“dog.guard”等等。它是完全匹配、单播的模式。
2. fanout![fanout 交换器](https://user-gold-cdn.xitu.io/2018/1/24/161260568fe5ce35?imageView2/0/w/1280/h/960/format/webp/ignore-error/1)每个发到 fanout 类型交换器的消息都会分到所有绑定的队列上去。fanout 交换器不处理路由键，只是简单的将队列绑定到交换器上，每个发送到交换器的消息都会被转发到与该交换器绑定的所有队列上。很像子网广播，每台子网内的主机都获得了一份复制的消息。fanout 类型转发消息是最快的。
3. topic![topic 交换器](https://user-gold-cdn.xitu.io/2018/1/24/161260569051565f?imageView2/0/w/1280/h/960/format/webp/ignore-error/1)topic 交换器通过模式匹配分配消息的路由键属性，将路由键和某个模式进行匹配，此时队列需要绑定到一个模式上。它将路由键和绑定键的字符串切分成单词，这些单词之间用点隔开。它同样也会识别两个通配符：符号“#”和符号“*”。#匹配0个或多个单词，*匹配不多不少一个单词。

# 认识KafKa

## 什么是KafKa

kafka是一种高吞吐量的分布式发布订阅消息系统，有如下特性：

- 通过O(1)的磁盘数据结构提供消息的持久化，这种结构对于即使数以TB的消息存储也能够保持长时间的稳定性能。
- 高吞吐量：即使是非常普通的硬件kafka也可以支持每秒数十万的消息。
- 支持通过kafka服务器和消费机集群来分区消息。
- 支持Hadoop并行数据加载。

Kafka的目的是提供一个发布订阅解决方案，它可以处理消费者规模的网站中的所有动作流数据。 这种动作（网页浏览，搜索和其他用户的行动）是在现代网络上的许多社会功能的一个关键因素。 这些数据通常是由于吞吐量的要求而通过处理日志和日志聚合来解决。 对于像Hadoop的一样的日志数据和离线分析系统，但又要求实时处理的限制，这是一个可行的解决方案。kafka的目的是通过Hadoop的并行加载机制来统一线上和离线的消息处理，也是为了通过集群机来提供实时的消费。

在Kafka有几个比较重要的概念：

- broker

  用于标识每一个Kafka服务，当然同一台服务器上可以开多个broker,只要他们的broker id不相同即可

- Topic

  消息主题，从逻辑上区分不同的消息类型

- Partition

  用于存放消息的队列，存放的消息都是有序的，同一主题可以分多个partition，如分多个partiton时，同样会以如partition1存放1,3,5消息,partition2存放2,4,6消息。

- Produce

  消息生产者，生产消息，可指定向哪个topic，topic哪个分区中生成消息。

- Consumer

  消息消费者，消费消息，同一消息只能被同一个consumer group中的consumer所消费。consumer是通过offset进行标识消息被消费的位置。当然consumer的个数取决于此topic所划分的partition，如同一group中的consumer个数大于partition的个数，多出的consumer将不会处理消息。

![59aff7b105142.png](https://user-gold-cdn.xitu.io/2017/9/10/8a1420eaca15a67acab2544858defacb?imageView2/0/w/1280/h/960/format/webp/ignore-error/1)

![59aff8007b758.png](https://user-gold-cdn.xitu.io/2017/9/10/2ba8f4c7db02f9607fc23722b97f3440?imageView2/0/w/1280/h/960/format/webp/ignore-error/1)

![59aff8161052f.png](https://user-gold-cdn.xitu.io/2017/9/10/30b3b5622f7be1c9325b52245eda3ee6?imageView2/0/w/1280/h/960/format/webp/ignore-error/1)

## 分布式搭建KafKa

服务器资源：

| 服务器名称     | 操作系统        | IP地址           |
| --------- | ----------- | -------------- |
| Server-01 | Centeos 6.5 | 172.16.128.144 |
| Server-02 | Centeos 6.5 | 172.16.128.145 |
| Server-03 | Centeos 6.5 | 172.16.128.146 |

在每台服务器上提前安装JDK 1.8

> 使用命令行Java -version查看是否成功

![59affc5f774b0.png](https://user-gold-cdn.xitu.io/2017/9/10/1a9e741a8ac2e93a8ae20c1a2a72f1a1?imageView2/0/w/1280/h/960/format/webp/ignore-error/1)

Kafka是通过Zookeeper进行管理群集，在每台服务器上先安装zookeeper。

### 搭建Zookeeper

zookeeper下载：

```
wget https://mirrors.cnnic.cn/apache/zookeeper/zookeeper-3.3.6/zookeeper-3.3.6.tar.gz
```

解压zookeeper:

```
tar -xvf zookeeper-3.3.6.tar.gz
mv zookeeper-3.3.6 zookeeper
```

修改配置文件：

```
cp conf/zoo_sample.cfg conf/zoo.cfg
vim conf/zoo.cfg
```

![59b398eae5a99.png](https://user-gold-cdn.xitu.io/2017/9/10/4971bdc3b2cca80beaf11c56ae93844c?imageView2/0/w/1280/h/960/format/webp/ignore-error/1)
配置文件参数说明:
tickTime这个时间是作为zookeeper服务器之间或客户端与服务器之间维持心跳的时间间隔,也就是说每个tickTime时间就会发送一个心跳。

initLimit这个配置项是用来配置zookeeper接受客户端（这里所说的客户端不是用户连接zookeeper服务器的客户端,而是zookeeper服务器集群中连接到leader的follower 服务器）初始化连接时最长能忍受多少个心跳时间间隔数。

当已经超过10个心跳的时间（也就是tickTime）长度后 zookeeper 服务器还没有收到客户端的返回信息,那么表明这个客户端连接失败。总的时间长度就是 10*2000=20秒。

syncLimit这个配置项标识leader与follower之间发送消息,请求和应答时间长度,最长不能超过多少个tickTime的时间长度,总的时间长度就是5*2000=10秒。

dataDir顾名思义就是zookeeper保存数据的目录,默认情况下zookeeper将写数据的日志文件也保存在这个目录里；

clientPort这个端口就是客户端连接Zookeeper服务器的端口,Zookeeper会监听这个端口接受客户端的访问请求；

server.A=B:C:D中的A是一个数字,表示这个是第几号服务器,B是这个服务器的IP地址，C第一个端口用来集群成员的信息交换,表示这个服务器与集群中的leader服务器交换信息的端口，D是在leader挂掉时专门用来进行选举leader所用的端口。

创建ServerID标识:
除了修改zoo.cfg配置文件外,zookeeper集群模式下还要配置一个myid文件,这个文件需要放在dataDir目录下。

这个文件里面有一个数据就是A的值（该A就是zoo.cfg文件中server.A=B:C:D中的A）,在zoo.cfg文件中配置的dataDir路径中创建myid文件。

在172.16.128.144服务器上创建myid文件，并设置为1，同时与zoo.cfg文件里面的server.1对应，如下：

```
echo "1" > /root/applicaton/zookeeper_app/zookeeper/data/myid
```

将上述配置好的文件通scp命令分别复制到server-02,server-03上面

```
scp /root/application/zookeeper_app/zookeeper root@172.16.128.145 /root/application/zookeeper_app/
scp /root/application/zookeeper_app/zookeeper root@172.16.128.146 /root/application/zookeeper_app/
#修改server-02 myid文件
echo "2" > /root/application/zookeeper_app/zookeeper/data/myid
#个性server-03 myid文件
echo "3" > /root/application/zookeeper_app/zookeeper/data/myid
```

启动各服务器上的zookeeper:

```
../zookeeper/bin/zkServer.sh start &
```

查看zookeeper状态：

```
../zookeeper/bin/zkServer.sh status
```

查看状态会看到其中一台服务器的mode为leader，其他两台为follower

![59b3996ede01f.png](https://user-gold-cdn.xitu.io/2017/9/10/9d1cf96d63eb04097deff6dbf498f69c?imageView2/0/w/1280/h/960/format/webp/ignore-error/1)

![59b39957604a7.png](https://user-gold-cdn.xitu.io/2017/9/10/6e83366136480d60dd81dc8d16590e83?imageView2/0/w/1280/h/960/format/webp/ignore-error/1)

### 搭建Kafka

kafka下载:

```
wget https://www.apache.org/dyn/closer.cgi?path=/kafka/0.11.0.0/kafka_2.11-0.11.0.0.tgz
```

解压kafka:

```
tar -xvf kafka_2.11-0.11.0.0.tgz
mv kafka_2.11-0.11.0.0 kafka
```

修改配置文件：

```
vim config/server.properties
#server-01
broker.id=1
listeners=PLAINTEXT://172.16.128.144:9092
log.dirs=/root/application/kafka_app/kafka/kafka-logs
num.partitions = 2
zookeeper.connect=172.16.128.144:2181,172.16.128.145:2181,172.16.128.146:2181
#server-02
broker.id=2
listeners=PLAINTEXT://172.16.128.145:9092
log.dirs=/root/application/kafka_app/kafka/kafka-logs
num.partitions = 2
zookeeper.connect=172.16.128.144:2181,172.16.128.145:2181,172.16.128.146:2181
#server-03
broker.id=3
listeners=PLAINTEXT://172.16.128.146:9092
log.dirs=/root/application/kafka_app/kafka/kafka-logs
num.partitions = 2
zookeeper.connect=172.16.128.144:2181,172.16.128.145:2181,172.16.128.146:2181
```

配置文件参数说明：
broker.id broker唯一标识
listeners kafka监听IP及安全方式
log.dirs 日志存储
num.partitions 创建topic时默认partition数量
zookeeper.connect zookeeper服务器地址

启动各服务器kafka：

```
../kafka/bin/kafka-server-start.sh ../config/server.properties &
```

查看kafka状态可以通过命令行执行jps或pa -aux 或netstat -ntlp
利用netstat -ntlp会看服务器监听的9092接口。
![59b3ab337ace7.png](data:image/svg+xml;utf8,)

# 使用KafKa

## Kafka Console

### topic

创建

```
./bin/kafka-topics.sh --zookeeper 172.16.128.144:2181,172.16.128.145:2181,172.16.128.146:2181 --create --topic my-test-topic --partitions 5 --replication-factor 1
```

查看

```
../kafka/bin/kafka-topic --list --zookeeper 172.16.128.144:9092
```

![59b3ad8a7109d.png](https://user-gold-cdn.xitu.io/2017/9/10/ab0995a3feb2bc4b85f9bf64d6b8a596?imageView2/0/w/1280/h/960/format/webp/ignore-error/1)

### Produce

```
./bin/kafka-console-producer.sh --topic my-test-topic --broker-list 172.16.128.144:9092,172.16.128.145:9092,172.16.128.146:9092
```

![59b3af92a9324.png](https://user-gold-cdn.xitu.io/2017/9/10/a27922860a531890838ab838a9355790?imageView2/0/w/1280/h/960/format/webp/ignore-error/1)

### Consumer

```
./bin/kafka-console-consumer.sh --bootstrap-server 172.16.128.144:9092,172.16.128.145:9092,172.16.128.146:9092 --topic my-test-topic --from-beginning
```

![59b3afa2ac56b.png](data:image/svg+xml;utf8,)

## Native JAVA API

### 创建Java Maven项目.

在Pom文件中引入”kafka-clients” jar包

```
<dependency>
    <groupId>org.apache.kafka</groupId>
    <artifactId>kafka-clients</artifactId>
    <version>0.11.0.0</version>
</dependency>
```

### Produce

```
private static String topic = "my-test-topic";
private Properties createProps() {
    Properties props = new Properties();
    props.put("bootstrap.servers", "172.16.128.144:9092,172.16.128.145:9092,172.16.128.146:9092");
    props.put("acks", "all");
    props.put("retries", 0);
    props.put("batch.size", 16384);
    props.put("linger.ms", 1);
    props.put("buffer.memory", 33554432);
    props.put("key.serializer", "org.apache.kafka.common.serialization.StringSerializer");
    props.put("value.serializer", "org.apache.kafka.common.serialization.StringSerializer");
    return props;
}
public void send() {
    Producer<String, String> producer = new KafkaProducer<String, String>(createProps());
    for (int i = 0; i < 10; i++) {
        producer.send(new ProducerRecord<String, String>(topic, "key:" + Integer.toString(i), "value:" + Integer.toString(i)));
    }
    producer.close();
}
```

### Consumer

```
private static String topic = "my-test-topic";
public void receiveTest() {

    Properties props = new Properties();
    props.put("bootstrap.servers", "172.16.128.144:9092,172.16.128.145:9092,172.16.128.146:9092");
    props.put("group.id", "test");
    props.put("enable.auto.commit", "true");
    props.put("auto.commit.interval.ms", "1000");
    props.put("session.timeout.ms", "30000");
    props.put("key.deserializer", "org.apache.kafka.common.serialization.StringDeserializer");
    props.put("value.deserializer", "org.apache.kafka.common.serialization.StringDeserializer");
    KafkaConsumer<String, String> consumer = new KafkaConsumer<String, String>(props);
    consumer.subscribe(Collections.singletonList(topic));
    try {
        while (true) {
            ConsumerRecords<String, String> records = consumer.poll(Long.MAX_VALUE);
            for (TopicPartition partition : records.partitions()) {
                List<ConsumerRecord<String, String>> partitionRecords = records.records(partition);
                for (ConsumerRecord<String, String> record : partitionRecords) {
                    System.out.println(record.offset() + ": " + record.value());
                }
                long lastOffset = partitionRecords.get(partitionRecords.size() - 1).offset();
                consumer.commitSync(Collections.singletonMap(partition, new OffsetAndMetadata(lastOffset + 1)));
            }
        }
    } finally {
        consumer.close();
    }
}
```

## Spring boot Kafka

Spring boot Kafka是由spring对kafka操作的一种封装，方便进行对kafka操作（Spring对Kafka的操作有spring-kaka和spring-integration-kafka,示例以spring-kafka操作kafka）。

### 创建spring boot项目。

在pom文件内引入”spring-kafka”jar

```
<properties>
    <project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>
    <project.reporting.outputEncoding>UTF-8</project.reporting.outputEncoding>
    <java.version>1.8</java.version>

    <spring-kafka.version>1.2.2.RELEASE</spring-kafka.version>
</properties>
<!-- spring-kafka -->
<dependency>
    <groupId>org.springframework.kafka</groupId>
    <artifactId>spring-kafka</artifactId>
    <version>${spring-kafka.version}</version>
</dependency>
<dependency>
    <groupId>org.springframework.kafka</groupId>
    <artifactId>spring-kafka-test</artifactId>
    <version>${spring-kafka.version}</version>
    <scope>test</scope>
</dependency>
```

### 配置spring application.yml

```
spring:
  kafka:
    bootstrap-servers: 172.16.128.144:9092,172.16.128.145:9092,172.16.128.146:9092
    template:
      default-topic: my-test-topic
    consumer:
      group-id: mytesttopicgroup
    listener:
      concurrency: 5
```

### Produce

添加produce配置java文件及处理文件。

SenderConfig.java

```
@Configuration
public class SenderConfig {
    @Value("${spring.kafka.bootstrap-servers}")
    private String bootstrapServers;

    @Bean
    public Map<String, Object> producerConfigs() {
        Map<String, Object> props = new HashMap<>();
        props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapServers);
        props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class);
        props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class);
        return props;
    }

    @Bean
    public ProducerFactory<String, String> producerFactory() {
        return new DefaultKafkaProducerFactory<>(producerConfigs());
    }

    @Bean
    public KafkaTemplate<String, String> kafkaTemplate() {
        return new KafkaTemplate<>(producerFactory());
    }

    @Bean
    public Sender sender() {
        return new Sender();
    }
```

Sender.java

```
public class Sender {
    private static final Logger LOGGER = LoggerFactory.getLogger(Sender.class);

    @Autowired
    private KafkaTemplate<String, String> kafkaTemplate;

    public void send(String topic, String data) {
        kafkaTemplate.send(topic, data);
    }
}
```

### Consumer

添加consumer配置java文件及处理文件。

ReceiverConfig.java

```
@Configuration
@EnableKafka
public class ReceiverConfig {
    @Value("${spring.kafka.bootstrap-servers}")
    private String bootstrapServers;

    @Value("${spring.kafka.consumer.group-id}")
    private String groupId;

    @Value("${spring.kafka.listener.concurrency}")
    private int concurrency;

    @Bean
    public Map<String, Object> consumerConfigs() {
        Map<String, Object> props = new HashMap<>();

        props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapServers);
        props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class);
        props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class);
        props.put(ConsumerConfig.GROUP_ID_CONFIG, groupId);

    

        return props;
    }

    @Bean
    public ConsumerFactory<String, String> consumerFactory() {
        return new DefaultKafkaConsumerFactory<>(consumerConfigs());
    }

    @Bean
    public ConcurrentKafkaListenerContainerFactory<String, String> kafkaListenerContainerFactory() {
        ConcurrentKafkaListenerContainerFactory<String, String> factory = new ConcurrentKafkaListenerContainerFactory<>();
        factory.setConsumerFactory(consumerFactory());
        factory.setConcurrency(concurrency); 
        return factory;
    }

    @Bean
    public Receiver receiver(){
        return new Receiver();
    }

}
```

Receiver.java

```
public class Receiver {

 @Autowired
 private MessageHandle messageHandle;
 private static final Logger LOGGER = LoggerFactory.getLogger(Receiver.class);
    
 private CountDownLatch latch0 = new CountDownLatch(5);
 private CountDownLatch latch1 = new CountDownLatch(5);
 private CountDownLatch latch2 = new CountDownLatch(5);
 private CountDownLatch latch3 = new CountDownLatch(5);
 private CountDownLatch latch4 = new CountDownLatch(5);

 @KafkaListener(id = "id0", topicPartitions = {@TopicPartition(topic = "${spring.kafka.template.default-topic}", partitions = {"0"})})
 public void listenPartition0(String message) {
    LOGGER.info("received message='{}'", message);
    LOGGER.info("thread ID:" + Thread.currentThread().getId());
    latch0.countDown();
 }

 @KafkaListener(id = "id1", topicPartitions = {@TopicPartition(topic = "${spring.kafka.template.default-topic}", partitions = {"1"})})
 public void listenPartition1(String message) {
    LOGGER.info("received message='{}'", message);
    LOGGER.info("thread ID:" + Thread.currentThread().getId());
    latch1.countDown();
 }

 @KafkaListener(id = "id2", topicPartitions = {@TopicPartition(topic = "${spring.kafka.template.default-topic}", partitions = {"2"})})
 public void listenPartition2(String message) {
    LOGGER.info("received message='{}'", message);
    LOGGER.info("thread ID:" + Thread.currentThread().getId());
    latch2.countDown();
 }

 @KafkaListener(id = "id3", topicPartitions = {@TopicPartition(topic = "${spring.kafka.template.default-topic}", partitions = {"3"})})
 public void listenPartition3(String message) {
    LOGGER.info("received message='{}'", message);
    LOGGER.info("thread ID:" + Thread.currentThread().getId());
    latch3.countDown();
 }

 @KafkaListener(id = "id4", topicPartitions = {@TopicPartition(topic = "${spring.kafka.template.default-topic}", partitions = {"4"})})
 public void listenPartition4(String message) {
    LOGGER.info("received message='{}'", message);
    LOGGER.info("thread ID:" + Thread.currentThread().getId());
    latch4.countDown();
 }
}
```

# 总结

到此kafka的搭建到使用都已结束，在消费kafka消息时，建议使用spring boot + spring kafka。
由于spring boot打包部署比较方便，同一台机器上可以开多个spring boot也就是开多个进程的consumer。
如不想开多个进程处理，在spring kafka 中@KafkaListener注解可针对不同的topic，不同的partition消费，也可开不同的线程进行消费kafka。

kafka还有很多需要学习的地方，如：kafka-stream,topic的管理，topic的消息分布情况，查看当前有多少个consumer group，每个consumer的offset是多少等等。

# 消息队列之 Kafka

# Kafka 特点

Kafka 最早是由 LinkedIn 公司开发一种分布式的基于发布/订阅的消息系统，之后成为 Apache 的顶级项目。主要特点如下：

### 1. 同时为发布和订阅提供高吞吐量

Kafka 的设计目标是以时间复杂度为 O(1) 的方式提供消息持久化能力，即使对TB 级以上数据也能保证常数时间的访问性能。即使在非常廉价的商用机器上也能做到单机支持每秒 100K 条消息的传输。

### 2. 消息持久化

将消息持久化到磁盘，因此可用于批量消费，例如 ETL 以及实时应用程序。通过将数据持久化到硬盘以及 replication 防止数据丢失。

### 3. 分布式

支持 Server 间的消息分区及分布式消费，同时保证每个 partition 内的消息顺序传输。这样易于向外扩展，所有的producer、broker 和 consumer 都会有多个，均为分布式的。无需停机即可扩展机器。

### 4. 消费消息采用 pull 模式

消息被处理的状态是在 consumer 端维护，而不是由 server 端维护，broker 无状态，consumer 自己保存 offset。

### 5. 支持 online 和 offline 的场景。

同时支持离线数据处理和实时数据处理。

# Kafka 中的基本概念

![img](https://user-gold-cdn.xitu.io/2018/1/24/1612607ba2bc04f8?imageView2/0/w/1280/h/960/format/webp/ignore-error/1)

### 1. Broker

Kafka 集群中的一台或多台服务器统称为 Broker

### 2. Topic

每条发布到 Kafka 的消息都有一个类别，这个类别被称为 Topic 。（物理上不同 Topic 的消息分开存储。逻辑上一个 Topic 的消息虽然保存于一个或多个broker上，但用户只需指定消息的 Topic 即可生产或消费数据而不必关心数据存于何处）

### 3. Partition

Topic 物理上的分组，一个 Topic 可以分为多个 Partition ，每个 Partition 是一个有序的队列。Partition 中的每条消息都会被分配一个有序的 id（offset）

### 4. Producer

消息和数据的生产者，可以理解为往 Kafka 发消息的客户端

### 5. Consumer

消息和数据的消费者，可以理解为从 Kafka 取消息的客户端

### 6. Consumer Group

每个 Consumer 属于一个特定的 Consumer Group（可为每个 Consumer 指定Group Name，若不指定 Group Name 则属于默认的 Group）。 这是 Kafka 用来实现一个 Topic 消息的广播（发给所有的 Consumer ）和单播（发给任意一个 Consumer ）的手段。一个 Topic 可以有多个 Consumer Group。Topic 的消息会复制（不是真的复制，是概念上的）到所有的 Consumer Group，但每个 Consumer Group 只会把消息发给该 Consumer Group 中的一个 Consumer。如果要实现广播，只要每个 Consumer 有一个独立的 Consumer Group 就可以了。如果要实现单播只要所有的 Consumer 在同一个 Consumer Group 。用 Consumer Group 还可以将 Consumer 进行自由的分组而不需要多次发送消息到不同的 Topic 。

## 简介

### RocketMQ 特点

RocketMQ 是阿里巴巴在2012年开源的分布式消息中间件，目前已经捐赠给 Apache 软件基金会，并于2017年9月25日成为 Apache 的顶级项目。作为经历过多次阿里巴巴双十一这种“超级工程”的洗礼并有稳定出色表现的国产中间件，以其高性能、低延时和高可靠等特性近年来已经也被越来越多的国内企业使用。其主要特点有：

#### 1. 灵活可扩展性

RocketMQ 天然支持集群，其核心四组件（Name Server、Broker、Producer、Consumer）每一个都可以在没有单点故障的情况下进行水平扩展。

#### 2. 海量消息堆积能力

RocketMQ 采用零拷贝原理实现超大的消息的堆积能力，据说单机已可以支持亿级消息堆积，而且在堆积了这么多消息后依然保持写入低延迟。

#### 3. 支持顺序消息

可以保证消息消费者按照消息发送的顺序对消息进行消费。顺序消息分为全局有序和局部有序，一般推荐使用局部有序，即生产者通过将某一类消息按顺序发送至同一个队列来实现。

#### 4. 多种消息过滤方式

消息过滤分为在服务器端过滤和在消费端过滤。服务器端过滤时可以按照消息消费者的要求做过滤，优点是减少不必要消息传输，缺点是增加了消息服务器的负担，实现相对复杂。消费端过滤则完全由具体应用自定义实现，这种方式更加灵活，缺点是很多无用的消息会传输给消息消费者。

#### 5. 支持事务消息

RocketMQ 除了支持普通消息，顺序消息之外还支持事务消息，这个特性对于分布式事务来说提供了又一种解决思路。

#### 6. 回溯消费

回溯消费是指消费者已经消费成功的消息，由于业务上需求需要重新消费，RocketMQ 支持按照时间回溯消费，时间维度精确到毫秒，可以向前回溯，也可以向后回溯。

### 基本概念

下面是一张 RocketMQ 的部署结构图，里面涉及了 RocketMQ 核心的四大组件：Name Server、Broker、Producer、Consumer ，每个组件都可以部署成集群模式进行水平扩展。

![部署结构图](https://user-gold-cdn.xitu.io/2018/5/7/1633a1324de1781d?imageView2/0/w/1280/h/960/format/webp/ignore-error/1)

#### 生产者

生产者（Producer）负责产生消息，生产者向消息服务器发送由业务应用程序系统生成的消息。 RocketMQ 提供了三种方式发送消息：同步、异步和单向。

##### 同步发送

同步发送指消息发送方发出数据后会在收到接收方发回响应之后才发下一个数据包。一般用于重要通知消息，例如重要通知邮件、营销短信。

##### 异步发送

异步发送指发送方发出数据后，不等接收方发回响应，接着发送下个数据包，一般用于可能链路耗时较长而对响应时间敏感的业务场景，例如用户视频上传后通知启动转码服务。

##### 单向发送

单向发送是指只负责发送消息而不等待服务器回应且没有回调函数触发，适用于某些耗时非常短但对可靠性要求并不高的场景，例如日志收集。

##### 生产者组

生产者组（Producer Group）是一类 Producer 的集合，这类 Producer 通常发送一类消息并且发送逻辑一致，所以将这些 Producer 分组在一起。从部署结构上看生产者通过 Producer Group 的名字来标记自己是一个集群。

#### 消费者

消费者（Consumer）负责消费消息，消费者从消息服务器拉取信息并将其输入用户应用程序。站在用户应用的角度消费者有两种类型：拉取型消费者、推送型消费者。

##### 拉取型消费者

拉取型消费者（Pull Consumer）主动从消息服务器拉取信息，只要批量拉取到消息，用户应用就会启动消费过程，所以 Pull 称为主动消费型。

##### 推送型消费者

推送型消费者（Push Consumer）封装了消息的拉取、消费进度和其他的内部维护工作，将消息到达时执行的回调接口留给用户应用程序来实现。所以 Push 称为被动消费类型，但从实现上看还是从消息服务器中拉取消息，不同于 Pull 的是 Push 首先要注册消费监听器，当监听器处触发后才开始消费消息。

##### 消费者组

消费者组（Consumer Group）一类 Consumer 的集合名称，这类 Consumer 通常消费同一类消息并且消费逻辑一致，所以将这些 Consumer 分组在一起。消费者组与生产者组类似，都是将相同角色的分组在一起并命名，分组是个很精妙的概念设计，RocketMQ 正是通过这种分组机制，实现了天然的消息负载均衡。消费消息时通过 Consumer Group 实现了将消息分发到多个消费者服务器实例，比如某个 Topic 有9条消息，其中一个 Consumer Group 有3个实例（3个进程或3台机器），那么每个实例将均摊3条消息，这也意味着我们可以很方便的通过加机器来实现水平扩展。

#### 消息服务器

消息服务器（Broker）是消息存储中心，主要作用是接收来自 Producer 的消息并存储， Consumer 从这里取得消息。它还存储与消息相关的元数据，包括用户组、消费进度偏移量、队列信息等。从部署结构图中可以看出 Broker 有 Master 和 Slave 两种类型，Master 既可以写又可以读，Slave 不可以写只可以读。从物理结构上看 Broker 的集群部署方式有四种：单 Master 、多 Master 、多 Master 多 Slave（同步刷盘）、多 Master多 Slave（异步刷盘）。

##### 单 Master

这种方式一旦 Broker 重启或宕机会导致整个服务不可用，这种方式风险较大，所以显然不建议线上环境使用。

##### 多 Master

所有消息服务器都是 Master ，没有 Slave 。这种方式优点是配置简单，单个 Master 宕机或重启维护对应用无影响。缺点是单台机器宕机期间，该机器上未被消费的消息在机器恢复之前不可订阅，消息实时性会受影响。

##### 多 Master 多 Slave（异步复制）

每个 Master 配置一个 Slave，所以有多对 Master-Slave，消息采用异步复制方式，主备之间有毫秒级消息延迟。这种方式优点是消息丢失的非常少，且消息实时性不会受影响，Master 宕机后消费者可以继续从 Slave 消费，中间的过程对用户应用程序透明，不需要人工干预，性能同多 Master 方式几乎一样。缺点是 Master 宕机时在磁盘损坏情况下会丢失极少量消息。

##### 多 Master 多 Slave（同步双写）

每个 Master 配置一个 Slave，所以有多对 Master-Slave ，消息采用同步双写方式，主备都写成功才返回成功。这种方式优点是数据与服务都没有单点问题，Master 宕机时消息无延迟，服务与数据的可用性非常高。缺点是性能相对异步复制方式略低，发送消息的延迟会略高。

#### 名称服务器

名称服务器（NameServer）用来保存 Broker 相关元信息并给 Producer 和 Consumer 查找 Broker 信息。NameServer 被设计成几乎无状态的，可以横向扩展，节点之间相互之间无通信，通过部署多台机器来标记自己是一个伪集群。每个 Broker 在启动的时候会到 NameServer 注册，Producer 在发送消息前会根据 Topic 到 NameServer 获取到 Broker 的路由信息，Consumer 也会定时获取 Topic 的路由信息。所以从功能上看应该是和 ZooKeeper 差不多，据说 RocketMQ 的早期版本确实是使用的 ZooKeeper ，后来改为了自己实现的 NameServer 。

#### 消息

消息（Message）就是要传输的信息。一条消息必须有一个主题（Topic），主题可以看做是你的信件要邮寄的地址。一条消息也可以拥有一个可选的标签（Tag）和额处的键值对，它们可以用于设置一个业务 key 并在 Broker 上查找此消息以便在开发期间查找问题。

##### 主题

主题（Topic）可以看做消息的规类，它是消息的第一级类型。比如一个电商系统可以分为：交易消息、物流消息等，一条消息必须有一个 Topic 。Topic 与生产者和消费者的关系非常松散，一个 Topic 可以有0个、1个、多个生产者向其发送消息，一个生产者也可以同时向不同的 Topic 发送消息。一个 Topic 也可以被 0个、1个、多个消费者订阅。

##### 标签

标签（Tag）可以看作子主题，它是消息的第二级类型，用于为用户提供额外的灵活性。使用标签，同一业务模块不同目的的消息就可以用相同 Topic 而不同的 Tag 来标识。比如交易消息又可以分为：交易创建消息、交易完成消息等，一条消息可以没有 Tag 。标签有助于保持您的代码干净和连贯，并且还可以为 RocketMQ 提供的查询系统提供帮助。

##### 消息队列

消息队列（Message Queue），主题被划分为一个或多个子主题，即消息队列。一个 Topic 下可以设置多个消息队列，发送消息时执行该消息的 Topic ，RocketMQ 会轮询该 Topic 下的所有队列将消息发出去。下图 Broker 内部消息情况：

![Broker 内部消息](https://user-gold-cdn.xitu.io/2018/5/7/1633a140bc30323f?imageView2/0/w/1280/h/960/format/webp/ignore-error/1)

##### 消息消费模式

消息消费模式有两种：集群消费（Clustering）和广播消费（Broadcasting）。默认情况下就是集群消费，该模式下一个消费者集群共同消费一个主题的多个队列，一个队列只会被一个消费者消费，如果某个消费者挂掉，分组内其它消费者会接替挂掉的消费者继续消费。而广播消费消息会发给消费者组中的每一个消费者进行消费。

##### 消息顺序

消息顺序（Message Order）有两种：顺序消费（Orderly）和并行消费（Concurrently）。顺序消费表示消息消费的顺序同生产者为每个消息队列发送的顺序一致，所以如果正在处理全局顺序是强制性的场景，需要确保使用的主题只有一个消息队列。并行消费不再保证消息顺序，消费的最大并行数量受每个消费者客户端指定的线程池限制。

## 工程实例

### Java 访问 RocketMQ 实例

RocketMQ 目前支持 Java、C++、Go 三种语言访问，按惯例以 Java 语言为例看下如何用 RocketMQ 来收发消息的。

#### 引入依赖

```
  <dependency>
      <groupId>org.apache.rocketmq</groupId>
      <artifactId>rocketmq-client</artifactId>
      <version>4.2.0</version>
  </dependency>
复制代码
```

添加 RocketMQ 客户端访问支持，具体版本和安装的 RocketMQ 版本一致即可。

#### 消息生产者

```
package org.study.mq.rocketMQ.java;

import org.apache.rocketmq.client.producer.DefaultMQProducer;
import org.apache.rocketmq.client.producer.SendResult;
import org.apache.rocketmq.common.message.Message;
import org.apache.rocketmq.remoting.common.RemotingHelper;

public class Producer {

    public static void main(String[] args) throws Exception {
        //创建一个消息生产者，并设置一个消息生产者组
        DefaultMQProducer producer = new DefaultMQProducer("niwei_producer_group");

        //指定 NameServer 地址
        producer.setNamesrvAddr("localhost:9876");

        //初始化 Producer，整个应用生命周期内只需要初始化一次
        producer.start();

        for (int i = 0; i < 100; i++) {
            //创建一条消息对象，指定其主题、标签和消息内容
            Message msg = new Message(
                    "topic_example_java" /* 消息主题名 */,
                    "TagA" /* 消息标签 */,
                    ("Hello Java demo RocketMQ " + i).getBytes(RemotingHelper.DEFAULT_CHARSET) /* 消息内容 */
            );

            //发送消息并返回结果
            SendResult sendResult = producer.send(msg);

            System.out.printf("%s%n", sendResult);
        }

        // 一旦生产者实例不再被使用则将其关闭，包括清理资源，关闭网络连接等
        producer.shutdown();
    }
}
复制代码
```

示例中用 DefaultMQProducer 类来创建一个消息生产者，通常一个应用创建一个 DefaultMQProducer 对象，所以一般由应用来维护生产者对象，可以其设置为全局对象或者单例。该类构造函数入参 producerGroup 是消息生产者组的名字，无论生产者还是消费者都必须给出 GroupName ，并保证该名字的唯一性，ProducerGroup 发送普通的消息时作用不大，后面介绍分布式事务消息时会用到。

接下来指定 NameServer 地址和调用 start 方法初始化，在整个应用生命周期内只需要调用一次 start 方法。

初始化完成后，调用 send 方法发送消息，示例中只是简单的构造了100条同样的消息发送，其实一个 Producer 对象可以发送多个主题多个标签的消息，消息对象的标签可以为空。send 方法是同步调用，只要不抛异常就标识成功。

最后应用退出时调用 shutdown 方法清理资源、关闭网络连接，从服务器上注销自己，通常建议应用在 JBOSS、Tomcat 等容器的退出钩子里调用 shutdown 方法。

#### 消息消费者

```
package org.study.mq.rocketMQ.java;

import org.apache.rocketmq.client.consumer.DefaultMQPushConsumer;
import org.apache.rocketmq.client.consumer.listener.ConsumeConcurrentlyContext;
import org.apache.rocketmq.client.consumer.listener.ConsumeConcurrentlyStatus;
import org.apache.rocketmq.client.consumer.listener.MessageListenerConcurrently;
import org.apache.rocketmq.common.consumer.ConsumeFromWhere;
import org.apache.rocketmq.common.message.MessageExt;

import java.io.UnsupportedEncodingException;
import java.util.Date;
import java.util.List;

public class Consumer {

    public static void main(String[] args) throws Exception {
        //创建一个消息消费者，并设置一个消息消费者组
        DefaultMQPushConsumer consumer = new DefaultMQPushConsumer("niwei_consumer_group");
        //指定 NameServer 地址
        consumer.setNamesrvAddr("localhost:9876");
        //设置 Consumer 第一次启动时从队列头部开始消费还是队列尾部开始消费
        consumer.setConsumeFromWhere(ConsumeFromWhere.CONSUME_FROM_FIRST_OFFSET);
        //订阅指定 Topic 下的所有消息
        consumer.subscribe("topic_example_java", "*");

        //注册消息监听器
        consumer.registerMessageListener(new MessageListenerConcurrently() {
            public ConsumeConcurrentlyStatus consumeMessage(List<MessageExt> list, ConsumeConcurrentlyContext context) {
                //默认 list 里只有一条消息，可以通过设置参数来批量接收消息
                if (list != null) {
                    for (MessageExt ext : list) {
                        try {
                            System.out.println(new Date() + new String(ext.getBody(), "UTF-8"));
                        } catch (UnsupportedEncodingException e) {
                            e.printStackTrace();
                        }
                    }
                }
                return ConsumeConcurrentlyStatus.CONSUME_SUCCESS;
            }
        });

        // 消费者对象在使用之前必须要调用 start 初始化
        consumer.start();
        System.out.println("消息消费者已启动");
    }
}
复制代码
```

示例中用 DefaultMQPushConsumer 类来创建一个消息消费者，通生产者一样一个应用一般创建一个 DefaultMQPushConsumer 对象，该对象一般由应用来维护，可以其设置为全局对象或者单例。该类构造函数入参 consumerGroup 是消息消费者组的名字，需要保证该名字的唯一性。

接下来指定 NameServer 地址和设置消费者应用程序第一次启动时从队列头部开始消费还是队列尾部开始消费。

接着调用 subscribe 方法给消费者对象订阅指定主题下的消息，该方法第一个参数是主题名，第二个擦书是标签名，示例表示订阅了主题名 topic_example_java 下所有标签的消息。

最主要的是注册消息监听器才能消费消息，示例中用的是 Consumer Push 的方式，即设置监听器回调的方式消费消息，默认监听回调方法中 List 里只有一条消息，可以通过设置参数来批量接收消息。

最后调用 start 方法初始化，在整个应用生命周期内只需要调用一次 start 方法。

#### 启动 Name Server

```
nohup sh bin/mqnamesrv &
tail -f ~/logs/rocketmqlogs/namesrv.log
复制代码
```

RocketMQ 核心的四大组件中 Name Server 和 Broker 都是由 RocketMQ 安装包提供的，所以要启动这两个应用才能提供消息服务。首先启动 Name Server，先确保你的机器中已经安装了与 RocketMQ 相匹配的 JDK ，并设置了环境变量 JAVA_HOME ，然后在 RocketMQ 的安装目录下执行 bin 目录下的 mqnamesrv ，默认会将该命令的执行情况输出到当前目录的 nohup.out 文件，最后跟踪日志文件查看 Name Server 的实际运行情况。

#### 启动 Broker

```
nohup sh bin/mqbroker -n localhost:9876 &
tail -f ~/logs/rocketmqlogs/broker.log
复制代码
```

同样也要确保你的机器中已经安装了与 RocketMQ 相匹配的 JDK ，并设置了环境变量 JAVA_HOME ，然后在 RocketMQ 的安装目录下执行 bin 目录下的 mqbroker ，默认会将该命令的执行情况输出到当前目录的 nohup.out 文件，最后跟踪日志文件查看 Broker 的实际运行情况。

#### 运行 Consumer

先运行 Consumer 类，这样当生产者发送消息的时候能在消费者后端看到消息记录。配置没问题的话会看到在控制台打印出`消息消费者已启动`

#### 运行 Producer

最后运行 Producer 类，在 Consumer 的控制台能看到接收的消息

![消费者接收到消息](https://user-gold-cdn.xitu.io/2018/5/7/1633a13cb8653a03?imageView2/0/w/1280/h/960/format/webp/ignore-error/1)

### Spring 整合 RocketMQ

不同于 RabbitMQ、ActiveMQ、Kafka 等消息中间件，Spring 社区已经通过多种方式提供了对这些中间件产品集成，例如通过 spring-jms 整合 ActiveMQ、通过 Spring AMQP 项目下的 spring-rabbit 整合 RabbitMQ、通过 spring-kafka 整合 kafka ，通过他们可以在 Spring 项目中更方便使用其 API 。目前在 Spring 框架中集成 RocketMQ 有三种方式，一是将消息生产者和消费者定义成 bean 对象交由 Spring 容器管理，二是使用 RocketMQ 社区的外部项目 rocketmq-jms（https://github.com/apache/rocketmq-externals/tree/master/rocketmq-jms）然后通过 spring-jms 方式集成使用，三是如果你的应用是基于 spring-boot 的，可以使用 RocketMQ 的外部项目 rocketmq-spring-boot-starter（https://github.com/apache/rocketmq-externals/tree/master/rocketmq-spring-boot-starter）比较方便的收发消息。

总的来讲 rocketmq-jms 项目实现了 JMS 1.1 规范的部分内容，目前支持 JMS 中的发布/订阅模型收发消息。rocketmq-spring-boot-starter 项目目前已经支持同步发送、异步发送、单向发送、顺序消费、并行消费、集群消费、广播消费等特性，如果比较喜欢 Spring Boot 这种全家桶的快速开发框架并且现有特性已满足业务要求可以使用该项目。当然从 API 使用上最灵活的还是第一种方式，下面以第一种方式为例简单看下Spring 如何集成 RocketMQ 的。

#### 消息生产者

```
package org.study.mq.rocketMQ.spring;

import org.apache.log4j.Logger;
import org.apache.rocketmq.client.producer.DefaultMQProducer;

public class SpringProducer {

    private Logger logger = Logger.getLogger(getClass());

    private String producerGroupName;

    private String nameServerAddr;

    private DefaultMQProducer producer;

    public SpringProducer(String producerGroupName, String nameServerAddr) {
        this.producerGroupName = producerGroupName;
        this.nameServerAddr = nameServerAddr;
    }

    public void init() throws Exception {
        logger.info("开始启动消息生产者服务...");

        //创建一个消息生产者，并设置一个消息生产者组
        producer = new DefaultMQProducer(producerGroupName);
        //指定 NameServer 地址
        producer.setNamesrvAddr(nameServerAddr);
        //初始化 SpringProducer，整个应用生命周期内只需要初始化一次
        producer.start();

        logger.info("消息生产者服务启动成功.");
    }

    public void destroy() {
        logger.info("开始关闭消息生产者服务...");

        producer.shutdown();

        logger.info("消息生产者服务已关闭.");
    }

    public DefaultMQProducer getProducer() {
        return producer;
    }
}
复制代码
```

消息生产者就是把生产者 DefaultMQProducer 对象的生命周期分成构造函数、init、destroy 三个方法，构造函数中将生产者组名、NameServer 地址作为变量由 Spring 容器在配置时提供，init 方法中实例化 DefaultMQProducer 对象、设置 NameServer 地址、初始化生产者对象，destroy 方法用于生产者对象销毁时清理资源。

#### 消息消费者

```
package org.study.mq.rocketMQ.spring;

import org.apache.log4j.Logger;
import org.apache.rocketmq.client.consumer.DefaultMQPushConsumer;
import org.apache.rocketmq.client.consumer.listener.MessageListenerConcurrently;
import org.apache.rocketmq.common.consumer.ConsumeFromWhere;

public class SpringConsumer {

    private Logger logger = Logger.getLogger(getClass());

    private String consumerGroupName;

    private String nameServerAddr;

    private String topicName;

    private DefaultMQPushConsumer consumer;

    private MessageListenerConcurrently messageListener;

    public SpringConsumer(String consumerGroupName, String nameServerAddr, String topicName, MessageListenerConcurrently messageListener) {
        this.consumerGroupName = consumerGroupName;
        this.nameServerAddr = nameServerAddr;
        this.topicName = topicName;
        this.messageListener = messageListener;
    }


    public void init() throws Exception {
        logger.info("开始启动消息消费者服务...");

        //创建一个消息消费者，并设置一个消息消费者组
        consumer = new DefaultMQPushConsumer(consumerGroupName);
        //指定 NameServer 地址
        consumer.setNamesrvAddr(nameServerAddr);
        //设置Consumer第一次启动是从队列头部开始消费还是队列尾部开始消费
        consumer.setConsumeFromWhere(ConsumeFromWhere.CONSUME_FROM_FIRST_OFFSET);

        //订阅指定 Topic 下的所有消息
        consumer.subscribe(topicName, "*");

        //注册消息监听器
        consumer.registerMessageListener(messageListener);

        // 消费者对象在使用之前必须要调用 start 初始化
        consumer.start();

        logger.info("消息消费者服务启动成功.");
    }

    public void destroy(){
        logger.info("开始关闭消息消费者服务...");

        consumer.shutdown();

        logger.info("消息消费者服务已关闭.");
    }

    public DefaultMQPushConsumer getConsumer() {
        return consumer;
    }

}
复制代码
```

同消息生产者类似，消息消费者是把生产者 DefaultMQPushConsumer 对象的生命周期分成构造函数、init、destroy 三个方法，具体含义在介绍 Java 访问 RocketMQ 实例时已经介绍过了，不再赘述。当然，有了消费者对象还需要消息监听器在接收到消息后执行具体的处理逻辑。

```
package org.study.mq.rocketMQ.spring;

import org.apache.log4j.Logger;
import org.apache.rocketmq.client.consumer.listener.ConsumeConcurrentlyContext;
import org.apache.rocketmq.client.consumer.listener.ConsumeConcurrentlyStatus;
import org.apache.rocketmq.client.consumer.listener.MessageListenerConcurrently;
import org.apache.rocketmq.common.message.MessageExt;

import java.io.UnsupportedEncodingException;
import java.util.List;

public class MessageListener implements MessageListenerConcurrently {

    private Logger logger = Logger.getLogger(getClass());

    public ConsumeConcurrentlyStatus consumeMessage(List<MessageExt> list, ConsumeConcurrentlyContext consumeConcurrentlyContext) {
        if (list != null) {
            for (MessageExt ext : list) {
                try {
                    logger.info("监听到消息 : " + new String(ext.getBody(), "UTF-8"));
                } catch (UnsupportedEncodingException e) {
                    e.printStackTrace();
                }
            }
        }
        return ConsumeConcurrentlyStatus.CONSUME_SUCCESS;
    }

}
复制代码
```

消息监听器类就是把前面 Java 示例中注册消息监听器时声明的匿名内部类代码抽取出来定义成单独一个类而已。

#### Spring 配置文件

因为只使用 Spring 框架集成，所以除了 Sping 框架核心 jar 包外不需要额外添加依赖包了。本例中将消息生产者和消息消费者分成两个配置文件，这样能更好的演示收发消息的效果。

```
<?xml version="1.0" encoding="UTF-8"?>
<beans xmlns="http://www.springframework.org/schema/beans"
       xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
       xsi:schemaLocation="http://www.springframework.org/schema/beans
        http://www.springframework.org/schema/beans/spring-beans-4.3.xsd">

    <bean id="producer" class="org.study.mq.rocketMQ.spring.SpringProducer" init-method="init" destroy-method="destroy">
        <constructor-arg name="nameServerAddr" value="localhost:9876"/>
        <constructor-arg name="producerGroupName" value="spring_producer_group"/>
    </bean>

</beans>
复制代码
```

消息生产者配置很简单，定义了一个消息生产者对象，该对象初始化时调用 init 方法，对象销毁前执行 destroy 方法，将 Name Server 地址和生产者组配置好。

```
<?xml version="1.0" encoding="UTF-8"?>
<beans xmlns="http://www.springframework.org/schema/beans"
       xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
       xsi:schemaLocation="http://www.springframework.org/schema/beans
        http://www.springframework.org/schema/beans/spring-beans-4.3.xsd">

    <bean id="messageListener" class="org.study.mq.rocketMQ.spring.MessageListener" />

    <bean id="consumer" class="org.study.mq.rocketMQ.spring.SpringConsumer" init-method="init" destroy-method="destroy">
        <constructor-arg name="nameServerAddr" value="localhost:9876"/>
        <constructor-arg name="consumerGroupName" value="spring_consumer_group"/>
        <constructor-arg name="topicName" value="spring-rocketMQ-topic" />
        <constructor-arg name="messageListener" ref="messageListener" />
    </bean>

</beans>
复制代码
```

消息消费者同消息生产者配置类似，多了一个消息监听器对象的定义和绑定。

#### 运行实例程序

按前述步骤 启动 Name Server 和 Broker，接着运行消息生产者和消息消费者程序，简化起见我们用两个单元测试类模拟这两个程序：

```
package org.study.mq.rocketMQ.spring;

import org.apache.rocketmq.client.producer.SendResult;
import org.apache.rocketmq.common.message.Message;
import org.apache.rocketmq.remoting.common.RemotingHelper;
import org.junit.Before;
import org.junit.Test;
import org.springframework.context.ApplicationContext;
import org.springframework.context.support.ClassPathXmlApplicationContext;

public class SpringProducerTest {

    private ApplicationContext container;

    @Before
    public void setup() {
        container = new ClassPathXmlApplicationContext("classpath:spring-producer.xml");
    }

    @Test
    public void sendMessage() throws Exception {
        SpringProducer producer = container.getBean(SpringProducer.class);

        for (int i = 0; i < 20; i++) {
            //创建一条消息对象，指定其主题、标签和消息内容
            Message msg = new Message(
                    "spring-rocketMQ-topic",
                    null,
                    ("Spring RocketMQ demo " + i).getBytes(RemotingHelper.DEFAULT_CHARSET) /* 消息内容 */
            );

            //发送消息并返回结果
            SendResult sendResult = producer.getProducer().send(msg);

            System.out.printf("%s%n", sendResult);
        }
    }

}
复制代码
```

SpringProducerTest 类模拟消息生产者发送消息。

```
package org.study.mq.rocketMQ.spring;

import org.junit.Before;
import org.junit.Test;
import org.springframework.context.ApplicationContext;
import org.springframework.context.support.ClassPathXmlApplicationContext;

public class SpringConsumerTest {

    private ApplicationContext container;

    @Before
    public void setup() {
        container = new ClassPathXmlApplicationContext("classpath:spring-consumer.xml");
    }

    @Test
    public void consume() throws Exception {
        SpringConsumer consumer = container.getBean(SpringConsumer.class);

        Thread.sleep(200 * 1000);

        consumer.destroy();
    }
}
复制代码
```

SpringConsumerTest 类模拟消息消费者者接收消息，在 consume 方法返回之前需要让当前线程睡眠一段时间，使消费者程序继续存活才能监听到生产者发送的消息。

分别运行 SpringProducerTest 类 和 SpringConsumerTest 类，在 SpringConsumerTest 的控制台能看到接收的消息：

![消费者接收到消息](https://user-gold-cdn.xitu.io/2018/5/7/1633a14603821d36?imageView2/0/w/1280/h/960/format/webp/ignore-error/1)

假如启动两个 SpringConsumerTest 类进程，因为它们属于同一消费者组，在 SpringConsumerTest 的控制台能看到它们均摊到了消息：

![消费者1](https://user-gold-cdn.xitu.io/2018/5/7/1633a148e72d8150?imageView2/0/w/1280/h/960/format/webp/ignore-error/1)

![消费者2](https://user-gold-cdn.xitu.io/2018/5/7/1633a14b1de647be?imageView2/0/w/1280/h/960/format/webp/ignore-error/1)